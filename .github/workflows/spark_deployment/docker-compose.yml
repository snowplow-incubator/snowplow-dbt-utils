version: '3'
services:
  spark-master:
    image: snowplow/spark-s3-iceberg:latest-iam
    command: ["/bin/bash", "-c", "/spark/sbin/start-master.sh -h spark-master && tail -f /spark/logs/spark--org.apache.spark.deploy.master.Master-1-*.out"]
    hostname: spark-master
    ports:
      - '8080:8080'
      - '7077:7077'
    environment: &spark-env
      SPARK_LOCAL_IP: spark-master
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
      AWS_REGION: eu-west-1
      AWS_DEFAULT_REGION: eu-west-1
      SOFTWARE_AMAZON_AWSSDK_HTTP_SERVICE_IMPL: "software.amazon.awssdk.http.apache.ApacheSdkHttpService"
    volumes: &spark-volumes
      - ./spark-defaults.conf:/spark/conf/spark-defaults.conf:ro
      - ./logs:/spark/logs
      - ./events:/tmp/spark-events
      - ~/.aws:/root/.aws:ro
    networks:
      - spark-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'

  spark-worker:
    image: snowplow/spark-s3-iceberg:latest-iam
    command: ["/bin/bash", "-c", "sleep 10 && /spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /spark/logs/spark--org.apache.spark.deploy.worker.Worker-*.out"]
    depends_on:
      - spark-master
    environment:
      <<: *spark-env
      SPARK_LOCAL_IP: spark-worker
      SPARK_MASTER: spark://spark-master:7077
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
    volumes: *spark-volumes
    networks:
      - spark-network
    deploy:
      resources:
        limits:
          memory: 2.5G
          cpus: '2'

  thrift-server:
    image: snowplow/spark-s3-iceberg:latest-iam
    command: >
      /bin/bash -c '
      sleep 30 &&
      /spark/sbin/start-thriftserver.sh
      --master spark://spark-master:7077
      --driver-memory 1g
      --executor-memory 2g
      --conf "spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog"
      --conf "spark.sql.catalog.spark_catalog.type=hive"
      --conf "spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions"
      --conf "spark.sql.defaultCatalog=iceberg_catalog"
      --hiveconf hive.server2.thrift.port=10000
      --hiveconf hive.server2.thrift.bind.host=0.0.0.0 &&
      tail -f /spark/logs/spark--org.apache.spark.sql.hive.thriftserver.HiveThriftServer2-*.out'
    ports:
      - '10000:10000'
      - '4040:4040'
    depends_on:
      - spark-master
      - spark-worker
    environment:
      <<: *spark-env
      SPARK_LOCAL_IP: thrift-server
      HIVE_SERVER2_THRIFT_PORT: 10000
      HIVE_SERVER2_THRIFT_BIND_HOST: 0.0.0.0
    volumes: *spark-volumes
    networks:
      - spark-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'

networks:
  spark-network:
    driver: bridge