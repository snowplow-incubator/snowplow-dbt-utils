version: '3'

networks:
  spark-network:
    driver: bridge

services:
  spark-master:
    image: snowplow/spark-s3-iceberg:v2
    platform: ${DOCKER_PLATFORM:-linux/amd64}
    command: ["/bin/bash", "-c", "/opt/spark/sbin/start-master.sh -h spark-master --properties-file /opt/spark/conf/spark-defaults.conf && tail -f /dev/null"]
    hostname: spark-master
    ports:
      - '8080:8080'
      - '7077:7077'
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_OPTS="-Dspark.driver.memory=2g"
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=eu-west-1
      - AWS_DEFAULT_REGION=eu-west-1
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    networks:
      - spark-network

  spark-worker:
    image: snowplow/spark-s3-iceberg:v2
    platform: ${DOCKER_PLATFORM:-linux/amd64}
    command: ["/bin/bash", "-c", "sleep 10 && /opt/spark/sbin/start-worker.sh spark://spark-master:7077 --properties-file /opt/spark/conf/spark-defaults.conf && tail -f /dev/null"]
    depends_on:
      - spark-master
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=4G
      - SPARK_EXECUTOR_MEMORY=3G
      - SPARK_LOCAL_IP=spark-worker
      - SPARK_MASTER=spark://spark-master:7077
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=eu-west-1
      - AWS_DEFAULT_REGION=eu-west-1
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    networks:
      - spark-network

  thrift-server:
    image: snowplow/spark-s3-iceberg:v2
    platform: ${DOCKER_PLATFORM:-linux/amd64}
    command: ["/bin/bash", "-c", "sleep 30 && /opt/spark/sbin/start-thriftserver.sh --master spark://spark-master:7077 --driver-memory 2g --executor-memory 3g --hiveconf hive.server2.thrift.port=10000 --hiveconf hive.server2.thrift.bind.host=0.0.0.0 --conf spark.sql.hive.thriftServer.async=true --conf spark.sql.hive.thriftServer.workerQueue.size=2000 --conf spark.sql.hive.thriftServer.maxWorkerThreads=100 --conf spark.sql.hive.thriftServer.minWorkerThreads=50 && tail -f /dev/null"]
    ports:
      - '10000:10000'
    depends_on:
      - spark-master
      - spark-worker
    environment:
      - SPARK_LOCAL_IP=thrift-server
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=eu-west-1
      - AWS_DEFAULT_REGION=eu-west-1
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    networks:
      - spark-network